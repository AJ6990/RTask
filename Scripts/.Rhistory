# get US Fips corresponsing to counties
countyFips <- countypop %>%
select(fips,county) %>%
as.data.frame() %>%
distinct()
# Get the first three digits of zip code
zip_us <- zip_us %>%
dplyr::mutate(zipCut = as.factor(substr(zipcode,1,3))) %>%
distinct() %>%
left_join(.,countyFips, by = "county")
# Find the first three digit that are prone to response based on the final trained model
proneZip <- Data %>%
select(zip3,county) %>%
filter(county>=1.2) %>%
distinct(zip3)
# Get the corresponding states and county using US data
zipData <- proneZip %>%
left_join(.,zip_us, by = c('zip3' = 'zipCut')) %>%
remove_missing()
zipOutput <- zip_us %>%
dplyr::mutate(value = ifelse(zip_us$zipcode %in% zipData$zipcode,1,0)) %>%
select(-zipCut) %>%
remove_missing() %>%
select(county,value,state,fips)
# Highlight counties with higher probabilities of response
plot_usmap( regions = "counties", data = zipOutput, values = "value", color = "red") +
scale_fill_continuous( "viridis",name = "Response", label = scales::comma) +
labs(title = "US counties", subtitle = "Counties with high probabilities of response") +
theme(legend.position = "right")
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9) , pfcol=rgb(0.2,0.5,0.5,0.5) , plwd=4 ,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=1,
#custom labels
vlcex=0.8)
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9) , pfcol=rgb(0.2,0.5,0.5,0.5) , plwd=4 ,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=0.6,
#custom labels
vlcex=0.8)
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9) , pfcol=rgb(0.2,0.5,0.5,0.5) , plwd=4 ,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8)
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9) , pfcol=rgb(0.2,0.5,0.5,0.5) , plwd=4 ,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8)
?radarchart
# radar plot
radarchart(ImpFeat2, axistype=2 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9) , pfcol=rgb(0.2,0.5,0.5,0.5) , plwd=4 ,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8)
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9) , pfcol=rgb(0.2,0.5,0.5,0.5) , plwd=4 ,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8)
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9) , pfcol=rgb(0.2,0.5,0.5,0.5) , plwd=4 ,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8, title = "Variable importance" )
caxislabels=seq(0,100,20)
seq(0,100,20)
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9, 0.9) , pfcol=rgb(0.2,0.5,0.5,0.5, 0.5) , plwd=4 ,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8, title = "Variable importance" )
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9, 0.9) , pfcol=rgb(0.2,0.5,0.5,0.5, 0.5) , plwd=5 ,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8, title = "Variable importance" )
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9, 0.9) , pfcol=rgb(0.2,0.5,0.5,0.5, 0.5) , plwd=4,
#custom the grid
cglcol="blue", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8, title = "Variable importance" )
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9, 0.9) , pfcol=rgb(0.2,0.5,0.5,0.5, 0.5) , plwd=4,
#custom the grid
cglcol="red", cglty=1, axislabcol="grey", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8, title = "Variable importance" )
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9, 0.9) , pfcol=rgb(0.2,0.5,0.5,0.5, 0.5) , plwd=4,
#custom the grid
cglcol="red", cglty=1, axislabcol="blue", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8, title = "Variable importance" )
View(ImpFeat2)
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9, 0.9) , pfcol=rgb(0.2,0.5,0.5,0.5, 0.5), plwd=4,
#custom the grid
cglcol="red", cglty=1, axislabcol="blue", caxislabels=seq(0,120,20), cglwd=0.8,
#custom labels
vlcex=0.8, title = "Variable importance" )
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9, 0.9) , pfcol=rgb(0.2,0.5,0.5,0.5, 0.5), plwd=4,seg = 5,
#custom the grid
cglcol="red", cglty=1, axislabcol="blue", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8, title = "Variable importance" )
Sys.setlocale("LC_ALL","English")
Sys.setenv(LANG = "en_US.UTF-8")
# libraries
library(caret)
library(tidyverse)
options(dplyr.summarise.inform=FALSE)  # suppress summarise grouping message in newer dplyr versions
library(lubridate)
library(rpart)
library(rattle)
library(rpart.plot)
library(usmap)
library(zipcodeR)
library(fmsb)
library(knitr)
options(knitr.kable.NA = '') # prints an empty cell instead of NA
library(yarrr)
library(formula.tools)
library(gtsummary)
library(kableExtra)
# Project path
project_path <- 'C:/Users/Alizadeh/Documents/Altran/Recruiting_Task'
# Metric functions
source('C:/Users/Alizadeh/Documents/Altran/Recruiting_Task/Functions/model_metricsglobal.R')
# Training and Test sets
source('C:/Users/Alizadeh/Documents/Altran/Recruiting_Task/Scripts/1_2_2_preprocessingForCase2.R')
knitr::opts_chunk$set(echo = FALSE, cache = FALSE, cache.lazy = FALSE,
warning = FALSE, message = F)
knitr::knit_hooks$set(inline = function(x) {
if(!is.numeric(x)){
x
} else {
prettyNum(round(x,2), big.mark=" ")
}
})
# all the objects are created outside of the RMD file for memory reasons
source('C:/Users/Alizadeh/Documents/Altran/Recruiting_Task/Scripts/4_source_markdown.R')
tibble('&nbsp;&nbsp;' = 'Predicted \n condition', ' ' = c('True', 'False'),
True = c('True positive', 'False negative'),
False = c('False positive', 'True negative')) %>%
kable('html', escape = F) %>%
kable_styling(bootstrap_options = c("striped", "hover"),
full_width = FALSE, fixed_thead = TRUE) %>%
collapse_rows(columns = 1) %>%
add_header_above(c(' ' = 2,
'Condition positive' = 2))
# Original data
InputData <-  read.csv(file.path(project_path,'Data/Recruiting_Task_InputData.csv'))
InputData <- dplyr::mutate_if(InputData, is.character, as.factor) %>%
dplyr::mutate(label = ifelse(label == "response",1,0))
# Divide data into train/test with a split ratio of 75::25
set.seed(888) # should be the same for all, so that the training/test sets are all the same
splitData <- createDataPartition(InputData$label, p = 0.75, list = FALSE)
trainingData<- InputData[splitData,]
testData<- InputData[-splitData,]
# Extract first digit of zip code as broad area and first 3 digits for county information
# Weight of evidence encoding is used to convert categorical variables with high cardinallity to numeric values
trainingData <- trainingData %>%
dplyr::mutate(broadArea = as.numeric(substr(zip.code,1,1))) %>% # First digit of zip code
dplyr::mutate(county = as.numeric(substr(zip.code,1,3)))  # First 3 digits of zip code
# Handling sports variable in Train set
# Like in training set, a new variable as "other" is defined
levels(trainingData$sports)[match("",levels(trainingData$sports))] <- "other"
trainingData$sports[trainingData$sports == ""] <- factor("other")
testData <- testData %>%
dplyr::mutate(broadArea = as.numeric(substr(zip.code,1,1))) %>% # First digit of zip code
dplyr::mutate(county = as.numeric(substr(zip.code,1,3)))  # First 3 digits of zip code
# Handling sports variable in Test set
# Like in training set, a new variable as "other" is defined
levels(testData$sports)[match("",levels(testData$sports))] <- "other"
testData$sports[testData$sports == ""] <- factor("other")
# A statistics overview of training set is implemented to get an overview of training set
trainingData %>%
select(-c(name,zip.code)) %>%
tbl_summary(by = label,missing_text = "Missing values") %>%
add_p(pvalue_fun = ~style_pvalue(.x, digits = 2)) %>%
bold_p() %>%
modify_header(label = "**Variable**") %>%
modify_spanning_header(update = starts_with("stat_") ~ "**Response**") %>%
add_overall() %>%
modify_footnote(
all_stat_cols() ~ "Median (IQR) or Frequency (%)") %>%
bold_labels() %>%
italicize_levels() %>%
as_flex_table()
# A statistics overview of test set is implemented to get an overview of test set
testData %>%
select(-c(name,zip.code)) %>%
tbl_summary(by = label,missing_text = "Missing values") %>%
add_p(pvalue_fun = ~style_pvalue(.x, digits = 2)) %>%
bold_p() %>%
modify_header(label = "**Variable**") %>%
modify_spanning_header(update = starts_with("stat_") ~ "**Response**") %>%
add_overall() %>%
modify_footnote(
all_stat_cols() ~ "Median (IQR) or Frequency (%)") %>%
bold_labels() %>%
italicize_levels() %>%
as_flex_table()
# cv AUC (values and plots)
for(name_algo in names(crossValidationList)){
cat('  \n####', name_algo, '  \n')
metrics <- crossValidationList[[name_algo]]
# Extract the AUC and F1 values to print them as part of the legend
aucs <- metrics$discrimination_metric %>%
pivot_longer(cols = -Metric) %>%
pivot_wider(names_from = Metric, values_from = value)
labels_auc <- paste0(aucs$name, '\n(', round(aucs$AUC, 3),')')
labels_prauc <- paste0(aucs$name, '\n(', round(aucs$prAUC, 3),')')
p_roc <- metrics$plots$ROC +
scale_color_discrete(labels = labels_auc)+
ggtitle('ROC')
p_rauc <- metrics$plots$Precision_recall +
scale_color_discrete(labels = labels_prauc)+
ggtitle('Precision-Recall curve')
print(p_roc)
print(p_rauc)
cat("  \n")
}
for(name_algo in names(crossValidationList)){
cat('  \n####', name_algo, '  \n')
metrics <- crossValidationList[[name_algo]]
# sort the varaibles based on the iportance
ImpFeat <- metrics$metrics %>%
mutate_if(is.numeric, ~ round(., 1)) %>%
rename(Importance = advertisementPrediction) %>%
select(Variable,Importance) %>%
arrange(desc(Importance))
# Prepare the ImpFeat in order to fit the plot
ImpFeat2 <-  as.data.frame(matrix( ImpFeat$Importance, ncol = dim(ImpFeat)[1]))
colnames(ImpFeat2) <- ImpFeat$Variable
ImpFeat2 <- rbind(rep(100,dim(ImpFeat)[1]) , rep(0,dim(ImpFeat)[1]) , ImpFeat2)
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9, 0.9) , pfcol=rgb(0.2,0.5,0.5,0.5, 0.5), plwd=4,seg = 5,
#custom the grid
cglcol="red", cglty=1, axislabcol="blue", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8, title = "Variable importance" )
# print(ImpFeatPlot)
cat("  \n")
}
list_metrics$plots$ROC
list_metrics$plots$Precision_recall
list_metrics$discrimination_plot
source(file.path(project_path, 'Scripts/1_2_3_preprocessingForFinalModel.R'))
# Create a data as combination of train and test
trainTestData <- Data %>%
select(-c(zip1,zip3))
# Train a decision tree classifier on whole data
FinalDT <- rpart(label~., data = trainTestData)
# Plot the rules to have a clear insight
rpart.plot(FinalDT,
type = 4,
under = TRUE)
# Get US zip codes together with county and state information
zip_us <- zip_code_db %>% select(zipcode,state,county)
# get US Fips corresponsing to counties
countyFips <- countypop %>%
select(fips,county) %>%
as.data.frame() %>%
distinct()
# Get the first three digits of zip code
zip_us <- zip_us %>%
dplyr::mutate(zipCut = as.factor(substr(zipcode,1,3))) %>%
distinct() %>%
left_join(.,countyFips, by = "county")
# Find the first three digit that are prone to response based on the final trained model
proneZip <- Data %>%
select(zip3,county) %>%
filter(county>=1.2) %>%
distinct(zip3)
# Get the corresponding states and county using US data
zipData <- proneZip %>%
left_join(.,zip_us, by = c('zip3' = 'zipCut')) %>%
remove_missing()
zipOutput <- zip_us %>%
dplyr::mutate(value = ifelse(zip_us$zipcode %in% zipData$zipcode,1,0)) %>%
select(-zipCut) %>%
remove_missing() %>%
select(county,value,state,fips)
# Highlight counties with higher probabilities of response
plot_usmap( regions = "counties", data = zipOutput, values = "value", color = "red") +
scale_fill_continuous( "viridis",name = "Response", label = scales::comma) +
labs(title = "US counties", subtitle = "Counties with high probabilities of response") +
theme(legend.position = "right")
Sys.setlocale("LC_ALL","English")
Sys.setenv(LANG = "en_US.UTF-8")
# libraries
library(caret)
library(tidyverse)
options(dplyr.summarise.inform=FALSE)  # suppress summarise grouping message in newer dplyr versions
library(lubridate)
library(rpart)
library(rattle)
library(rpart.plot)
library(usmap)
library(zipcodeR)
library(fmsb)
library(knitr)
options(knitr.kable.NA = '') # prints an empty cell instead of NA
library(yarrr)
library(formula.tools)
library(gtsummary)
library(kableExtra)
# Project path
project_path <- 'C:/Users/Alizadeh/Documents/Altran/Recruiting_Task'
# Metric functions
source('C:/Users/Alizadeh/Documents/Altran/Recruiting_Task/Functions/model_metricsglobal.R')
# Training and Test sets
source('C:/Users/Alizadeh/Documents/Altran/Recruiting_Task/Scripts/1_2_2_preprocessingForCase2.R')
knitr::opts_chunk$set(echo = FALSE, cache = FALSE, cache.lazy = FALSE,
warning = FALSE, message = F)
knitr::knit_hooks$set(inline = function(x) {
if(!is.numeric(x)){
x
} else {
prettyNum(round(x,2), big.mark=" ")
}
})
# all the objects are created outside of the RMD file for memory reasons
source('C:/Users/Alizadeh/Documents/Altran/Recruiting_Task/Scripts/4_source_markdown.R')
tibble('&nbsp;&nbsp;' = 'Predicted \n condition', ' ' = c('True', 'False'),
True = c('True positive', 'False negative'),
False = c('False positive', 'True negative')) %>%
kable('html', escape = F) %>%
kable_styling(bootstrap_options = c("striped", "hover"),
full_width = FALSE, fixed_thead = TRUE) %>%
collapse_rows(columns = 1) %>%
add_header_above(c(' ' = 2,
'Condition positive' = 2))
# Original data
InputData <-  read.csv(file.path(project_path,'Data/Recruiting_Task_InputData.csv'))
InputData <- dplyr::mutate_if(InputData, is.character, as.factor) %>%
dplyr::mutate(label = ifelse(label == "response",1,0))
# Divide data into train/test with a split ratio of 75::25
set.seed(888) # should be the same for all, so that the training/test sets are all the same
splitData <- createDataPartition(InputData$label, p = 0.75, list = FALSE)
trainingData<- InputData[splitData,]
testData<- InputData[-splitData,]
# Extract first digit of zip code as broad area and first 3 digits for county information
# Weight of evidence encoding is used to convert categorical variables with high cardinallity to numeric values
trainingData <- trainingData %>%
dplyr::mutate(broadArea = as.numeric(substr(zip.code,1,1))) %>% # First digit of zip code
dplyr::mutate(county = as.numeric(substr(zip.code,1,3)))  # First 3 digits of zip code
# Handling sports variable in Train set
# Like in training set, a new variable as "other" is defined
levels(trainingData$sports)[match("",levels(trainingData$sports))] <- "other"
trainingData$sports[trainingData$sports == ""] <- factor("other")
testData <- testData %>%
dplyr::mutate(broadArea = as.numeric(substr(zip.code,1,1))) %>% # First digit of zip code
dplyr::mutate(county = as.numeric(substr(zip.code,1,3)))  # First 3 digits of zip code
# Handling sports variable in Test set
# Like in training set, a new variable as "other" is defined
levels(testData$sports)[match("",levels(testData$sports))] <- "other"
testData$sports[testData$sports == ""] <- factor("other")
# A statistics overview of training set is implemented to get an overview of training set
trainingData %>%
select(-c(name,zip.code)) %>%
tbl_summary(by = label,missing_text = "Missing values") %>%
add_p(pvalue_fun = ~style_pvalue(.x, digits = 2)) %>%
bold_p() %>%
modify_header(label = "**Variable**") %>%
modify_spanning_header(update = starts_with("stat_") ~ "**Response**") %>%
add_overall() %>%
modify_footnote(
all_stat_cols() ~ "Median (IQR) or Frequency (%)") %>%
bold_labels() %>%
italicize_levels() %>%
as_flex_table()
# A statistics overview of test set is implemented to get an overview of test set
testData %>%
select(-c(name,zip.code)) %>%
tbl_summary(by = label,missing_text = "Missing values") %>%
add_p(pvalue_fun = ~style_pvalue(.x, digits = 2)) %>%
bold_p() %>%
modify_header(label = "**Variable**") %>%
modify_spanning_header(update = starts_with("stat_") ~ "**Response**") %>%
add_overall() %>%
modify_footnote(
all_stat_cols() ~ "Median (IQR) or Frequency (%)") %>%
bold_labels() %>%
italicize_levels() %>%
as_flex_table()
# cv AUC (values and plots)
for(name_algo in names(crossValidationList)){
cat('  \n####', name_algo, '  \n')
metrics <- crossValidationList[[name_algo]]
# Extract the AUC and F1 values to print them as part of the legend
aucs <- metrics$discrimination_metric %>%
pivot_longer(cols = -Metric) %>%
pivot_wider(names_from = Metric, values_from = value)
labels_auc <- paste0(aucs$name, '\n(', round(aucs$AUC, 3),')')
labels_prauc <- paste0(aucs$name, '\n(', round(aucs$prAUC, 3),')')
p_roc <- metrics$plots$ROC +
scale_color_discrete(labels = labels_auc)+
ggtitle('ROC')
p_rauc <- metrics$plots$Precision_recall +
scale_color_discrete(labels = labels_prauc)+
ggtitle('Precision-Recall curve')
print(p_roc)
print(p_rauc)
cat("  \n")
}
for(name_algo in names(crossValidationList)){
cat('  \n####', name_algo, '  \n')
metrics <- crossValidationList[[name_algo]]
# sort the varaibles based on the iportance
ImpFeat <- metrics$metrics %>%
mutate_if(is.numeric, ~ round(., 1)) %>%
rename(Importance = advertisementPrediction) %>%
select(Variable,Importance) %>%
arrange(desc(Importance))
# Prepare the ImpFeat in order to fit the plot
ImpFeat2 <-  as.data.frame(matrix( ImpFeat$Importance, ncol = dim(ImpFeat)[1]))
colnames(ImpFeat2) <- ImpFeat$Variable
ImpFeat2 <- rbind(rep(100,dim(ImpFeat)[1]) , rep(0,dim(ImpFeat)[1]) , ImpFeat2)
# radar plot
radarchart(ImpFeat2, axistype=1 ,
#custom polygon
pcol=rgb(0.2,0.5,0.5,0.9, 0.9) , pfcol=rgb(0.2,0.5,0.5,0.5, 0.5), plwd=4,seg = 5,
#custom the grid
cglcol="red", cglty=1, axislabcol="blue", caxislabels=seq(0,100,20), cglwd=0.8,
#custom labels
vlcex=0.8, title = "Variable importance")
cat("  \n")
}
list_metrics$plots$ROC
list_metrics$plots$Precision_recall
list_metrics$discrimination_plot
source(file.path(project_path, 'Scripts/1_2_3_preprocessingForFinalModel.R'))
# Create a data as combination of train and test
trainTestData <- Data %>%
select(-c(zip1,zip3))
# Train a decision tree classifier on whole data
FinalDT <- rpart(label~., data = trainTestData)
# Plot the rules to have a clear insight
rpart.plot(FinalDT,
type = 4,
under = TRUE)
# Get US zip codes together with county and state information
zip_us <- zip_code_db %>% select(zipcode,state,county)
# get US Fips corresponsing to counties
countyFips <- countypop %>%
select(fips,county) %>%
as.data.frame() %>%
distinct()
# Get the first three digits of zip code
zip_us <- zip_us %>%
dplyr::mutate(zipCut = as.factor(substr(zipcode,1,3))) %>%
distinct() %>%
left_join(.,countyFips, by = "county")
# Find the first three digit that are prone to response based on the final trained model
proneZip <- Data %>%
select(zip3,county) %>%
filter(county>=1.2) %>%
distinct(zip3)
# Get the corresponding states and county using US data
zipData <- proneZip %>%
left_join(.,zip_us, by = c('zip3' = 'zipCut')) %>%
remove_missing()
zipOutput <- zip_us %>%
dplyr::mutate(value = ifelse(zip_us$zipcode %in% zipData$zipcode,1,0)) %>%
select(-zipCut) %>%
remove_missing() %>%
select(county,value,state,fips)
# Highlight counties with higher probabilities of response
plot_usmap( regions = "counties", data = zipOutput, values = "value", color = "red") +
scale_fill_continuous( "viridis",name = "Response", label = scales::comma) +
labs(title = "US counties", subtitle = "Counties with high probabilities of response") +
theme(legend.position = "right")
